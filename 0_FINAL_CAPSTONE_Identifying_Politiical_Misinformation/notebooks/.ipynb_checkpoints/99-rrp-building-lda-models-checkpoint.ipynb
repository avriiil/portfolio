{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d6a8b34",
   "metadata": {},
   "source": [
    "# Building LDA Models\n",
    "\n",
    "In this notebook, we build the various LDA models used for our preliminary testing in the main **03-rrp-topic-modelling** notebook. We build them here because they are time-intensive (approx. 2hr per model). \n",
    "\n",
    "We save the models to disk (and Github repo) in this notebook and then import them in the main Topic Modelling notebook to evaluation and further use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef6c470",
   "metadata": {},
   "source": [
    "# 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a41a8537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.models import nmf\n",
    "from gensim.models import CoherenceModel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "328500b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6ff255",
   "metadata": {},
   "source": [
    "# 2. Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "367f9efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.4 s, sys: 8.04 s, total: 34.4 s\n",
      "Wall time: 37.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_parquet('/Users/richard/Desktop/data_cap3/processed/df_unique_tweets_hashtags_lemmatized_050521.parquet',\n",
    "                     engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00db5c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6145783, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e538d43",
   "metadata": {},
   "source": [
    "# 3. Pre-Processing for LDA\n",
    "\n",
    "APPROACH\n",
    "1. Create array containing documents only\n",
    "2. Create bag of words\n",
    "3. Map docs to BOW\n",
    "4. Create Tf-Idf\n",
    "5. Run LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ce28f0",
   "metadata": {},
   "source": [
    "## 3.1. Create Docs Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dbfa24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df.tweet_text.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "398a1bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6145783,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0427de43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ٱِنْطَلَق_1', 'مَرْكَز_1', 'ٱِتِّصال_1', 'مُوَحَّد_1',\n",
       "       'مُسْتَهْلِك_1', 'بَيِّن_1', 'إِنْشاء_1', 'لَجْنَة_1', 'دائِم_1',\n",
       "       'حِمايَة_1', 'مُسْتَهْلِك_1', 'بِناء_1', 'قَرار_1'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892b8052",
   "metadata": {},
   "source": [
    "## 3.2. Create BOW Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "226bd75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 33s, sys: 2.92 s, total: 2min 36s\n",
      "Wall time: 2min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create BOW dictionary\n",
    "dictionary = gensim.corpora.Dictionary(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "990697ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 أَنْتُم_1\n",
      "1 أَيّ_2\n",
      "2 اللَّه_1\n",
      "3 بَرَكَة_1\n",
      "4 تَأَخَّر_1\n",
      "5 خَيْر_1\n",
      "6 رَحْمَة_1\n",
      "7 سَلام_1\n",
      "8 ظِرّ_1\n",
      "9 عَلَى_1\n",
      "10 عَمِيل_1\n"
     ]
    }
   ],
   "source": [
    "# show first 11 words in dictionary\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5c055e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "890544"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68ef957",
   "metadata": {},
   "source": [
    "### 3.2.1. Filter Extreme Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f214cd7",
   "metadata": {},
   "source": [
    "**NOTE: Lots of experimenting to do here still. This is just a first random guess.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1ac4aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter extreme cases out of dictionary\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d47c281d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82457"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e5788d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_length = len(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e320e91b",
   "metadata": {},
   "source": [
    "## 3.3. Map Docs to BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7440a5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 7s, sys: 2min 5s, total: 4min 12s\n",
      "Wall time: 4min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# map docs to bag of words\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97a79831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 175 (\"تويتر_0\") appears 1 time(s).\n",
      "Word 253 (\"بَرْنامَج_1\") appears 2 time(s).\n",
      "Word 912 (\"تَخَلُّص_1\") appears 1 time(s).\n",
      "Word 1113 (\"تَنْحِيف_1\") appears 1 time(s).\n",
      "Word 1242 (\"حَقِيقِيّ_1\") appears 1 time(s).\n",
      "Word 1243 (\"مُسْتَعِير_1\") appears 1 time(s).\n",
      "Word 1244 (\"ٱِسْم_1\") appears 1 time(s).\n",
      "Word 1331 (\"وَزْن_1\") appears 1 time(s).\n",
      "Word 1348 (\"كِيلُو_1\") appears 1 time(s).\n",
      "Word 1676 (\"الكورس_0\") appears 1 time(s).\n",
      "Word 1677 (\"تَثْبِيت_1\") appears 1 time(s).\n",
      "Word 1680 (\"وَرْس_1\") appears 1 time(s).\n"
     ]
    }
   ],
   "source": [
    "# inspect\n",
    "bow_doc_300 = bow_corpus[300]\n",
    "\n",
    "for i in range(len(bow_doc_300)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time(s).\".format(bow_doc_300[i][0], \n",
    "                                                     dictionary[bow_doc_300[i][0]],\n",
    "                                                     bow_doc_300[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f264b7",
   "metadata": {},
   "source": [
    "# 4. Running LDA\n",
    "\n",
    "APPROACH\n",
    "1. Run LDA using 3 / 5 / 7 / 10 / 15 topics\n",
    "   - print top 20 words in topics\n",
    "2. Evaluate models\n",
    "   - Eyeballing Topic Contents using pyLDAvis \n",
    "   - Computing Topic Coherence using function\n",
    "3. Select best LDA model\n",
    "4. Refine performance using parameters\n",
    "   - adjust dictionary filtering cut-offs\n",
    "   - use different inputs (lemmatized vs. stemmed / bigrams vs. trigrams vs. no-grams) \n",
    "   - use BOW vs. Tf-Idf\n",
    "   - save models for future use\n",
    "   - adjust LDA parameters: alpha, beta, random_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6042e2",
   "metadata": {},
   "source": [
    "### Interpeting Topic Coherence\n",
    "\n",
    "Some good background info on [this SO thread](https://stackoverflow.com/questions/54762690/what-is-the-meaning-of-coherence-score-0-4-is-it-good-or-bad).\n",
    "- The overall coherence score of a topic is the average of the distances between words.\n",
    "    - .3 is bad\n",
    "    - .4 is low\n",
    "    - .55 is okay\n",
    "    - .65 might be as good as it is going to get\n",
    "    - .7 is nice\n",
    "    - .8 is unlikely and\n",
    "    - .9 is probably wrong\n",
    "- Adjust parameters (alpha, beta, random_state) to get better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0263efe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bea036a",
   "metadata": {},
   "source": [
    "## 4.1. Running LDA Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5d68c5",
   "metadata": {},
   "source": [
    "### 4.1.1. LDA with 5 Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68b670ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38min 40s, sys: 10min 42s, total: 49min 22s\n",
      "Wall time: 1h 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lda_model_5 = gensim.models.LdaMulticore(bow_corpus, \n",
    "                                         num_topics=5, \n",
    "                                         id2word=dictionary, \n",
    "                                         passes=4, \n",
    "                                         workers=2,\n",
    "                                         random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49287734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save 5-topic model to disk in github repo\n",
    "lda_model_5.save(\"/Users/richard/Desktop/springboard_repo/capstones/three/models/LDA_5_below15_above50_top100k.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f1b1aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.013*\"الله_1_0\" + 0.007*\"رياض_1_0\" + 0.006*\"ل_1_0\" + 0.005*\"قلب_3_0\" + 0.005*\"شركة_1_0\" + 0.005*\"دعم_1_0\" + 0.004*\"تنظيف_1_0\" + 0.004*\"أهلي_1_0\" + 0.004*\"رب_1_0\" + 0.004*\"سعودي_1_0\"\n",
      "Topic: 1 \n",
      "Words: 0.032*\"متابع_1_0\" + 0.030*\"بيع_1_0\" + 0.029*\"تويتر_0_0\" + 0.029*\"رتويت_0_0\" + 0.024*\"زيادة_1_0\" + 0.023*\"ٱنتصاب_1_0\" + 0.020*\"منتج_2_0\" + 0.020*\"قذف_1_0\" + 0.016*\"علاج_1_0\" + 0.016*\"تنفيذ_1_0\"\n",
      "Topic: 2 \n",
      "Words: 0.080*\"ساعة_1_0\" + 0.029*\"ماركة_1_0\" + 0.025*\"رياض_1_0\" + 0.024*\"نسائي_1_0\" + 0.024*\"مظلة_1_0\" + 0.021*\"كيلو_1_0\" + 0.020*\"أبى-a_1_0\" + 0.018*\"خارج_1_0\" + 0.017*\"طقم_1_0\" + 0.017*\"علبة_1_0\"\n",
      "Topic: 3 \n",
      "Words: 0.090*\"دون_1_0\" + 0.059*\"سداد_1_0\" + 0.055*\"مكيفات_1_0\" + 0.050*\"غسيل_1_0\" + 0.049*\"قرض_1_0\" + 0.047*\"بنك_1_0\" + 0.045*\"تسديد_1_0\" + 0.041*\"متعثر_1_0\" + 0.039*\"قلم_1_0\" + 0.035*\"قمة_1_0\"\n",
      "Topic: 4 \n",
      "Words: 0.114*\"جديد_1_0\" + 0.069*\"سكس_0_0\" + 0.037*\"فيلم_1_0\" + 0.030*\"ني_1_0\" + 0.027*\"محرم_1_0\" + 0.025*\"خادم_1_0\" + 0.024*\"قديم_1_0\" + 0.023*\"مترجم_1_0\" + 0.023*\"دفع_1_0\" + 0.021*\"عامل_2_0\"\n"
     ]
    }
   ],
   "source": [
    "# for each topic, print words occuring in that topic\n",
    "for idx, topic in lda_model_5.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c9f7cb",
   "metadata": {},
   "source": [
    "- Topic 0: ...\n",
    "- Topic 1: ...\n",
    "- Topic 2: ...\n",
    "- Topic 3: ...\n",
    "- Topic 4: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea42a32e",
   "metadata": {},
   "source": [
    "### 4.1.2. LDA with 3 Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11e4ab27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37min 32s, sys: 9min 52s, total: 47min 24s\n",
      "Wall time: 58min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lda_model_3 = gensim.models.LdaMulticore(bow_corpus, \n",
    "                                         num_topics=3, \n",
    "                                         id2word=dictionary, \n",
    "                                         passes=4, \n",
    "                                         workers=2,\n",
    "                                         random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "069cf8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save 3-topic model to disk in github repo\n",
    "lda_model_3.save(\"/Users/richard/Desktop/springboard_repo/capstones/three/models/LDA_3_below15_above50_top100k.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d7aabe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.015*\"الله_1_0\" + 0.006*\"ل_1_0\" + 0.006*\"قلب_3_0\" + 0.005*\"دعم_1_0\" + 0.005*\"أهلي_1_0\" + 0.005*\"رب_1_0\" + 0.004*\"سعودي_1_0\" + 0.004*\"اللهم_1_0\" + 0.004*\"أن_1_0\" + 0.004*\"أنا_1_0\"\n",
      "Topic: 1 \n",
      "Words: 0.042*\"رياض_1_0\" + 0.036*\"تنظيف_1_0\" + 0.035*\"شركة_1_0\" + 0.018*\"أثاث_1_0\" + 0.015*\"مجلس_1_0\" + 0.014*\"واصل_1_0\" + 0.012*\"طبيعي_1_0\" + 0.011*\"نقل_1_0\" + 0.011*\"مظلة_1_0\" + 0.010*\"مكيفات_1_0\"\n",
      "Topic: 2 \n",
      "Words: 0.041*\"ساعة_1_0\" + 0.028*\"سعر_1_0\" + 0.021*\"جديد_1_0\" + 0.017*\"عرض_1_0\" + 0.016*\"ماركة_1_0\" + 0.015*\"خاص_1_0\" + 0.015*\"ضمان_1_0\" + 0.013*\"رجل_1_0\" + 0.012*\"سنة_1_0\" + 0.012*\"نسائي_1_0\"\n"
     ]
    }
   ],
   "source": [
    "# for each topic, print words occuring in that topic\n",
    "for idx, topic in lda_model_3.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a241df",
   "metadata": {},
   "source": [
    "### 4.1.3. LDA with 7 Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2f72e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38min 18s, sys: 11min 29s, total: 49min 47s\n",
      "Wall time: 59min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lda_model_7 = gensim.models.LdaMulticore(bow_corpus, \n",
    "                                         num_topics=7, \n",
    "                                         id2word=dictionary, \n",
    "                                         passes=4, \n",
    "                                         workers=2,\n",
    "                                         random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f46058be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save 7-topic model to disk in github repo\n",
    "lda_model_7.save(\"/Users/richard/Desktop/springboard_repo/capstones/three/models/LDA_7_below15_above50_top100k.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7611811f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.063*\"شيك_1_0\" + 0.048*\"قهوة_1_0\" + 0.036*\"مول_1_0\" + 0.032*\"لذيذ_1_0\" + 0.031*\"إجازة_1_0\" + 0.029*\"ميل_1_0\" + 0.025*\"شاي_1_0\" + 0.024*\"ٱستمتع_1_0\" + 0.023*\"لذة_1_0\" + 0.015*\"كافي_1_0\"\n",
      "Topic: 1 \n",
      "Words: 0.057*\"توفيرحجوزات_0_0\" + 0.050*\"اوراوا_0_0\" + 0.026*\"هواري_1_0\" + 0.025*\"دندراوي_0_0\" + 0.014*\"الحبسي_0_0\" + 0.014*\"هيريرا_0_0\" + 0.014*\"انييستا_0_0\" + 0.014*\"تاعبك_0_0\" + 0.014*\"توحا_0_0\" + 0.013*\"ربيروف_0_0\"\n",
      "Topic: 2 \n",
      "Words: 0.383*\"الميكرسكوب_0_0\" + 0.047*\"بشرة_1_0\" + 0.033*\"نخبة_1_0\" + 0.029*\"ستار_1_0\" + 0.027*\"ياباني_1_0\" + 0.025*\"ٱستعادة_1_0\" + 0.017*\"عظمي_1_0\" + 0.016*\"سقطري_0_0\" + 0.015*\"مارسيل_0_0\" + 0.010*\"إيجابيات_1_0\"\n",
      "Topic: 3 \n",
      "Words: 0.101*\"كوبلاي_0_0\" + 0.031*\"هاذا_0_0\" + 0.022*\"سيرناي_0_0\" + 0.021*\"رأس-ai_1_0\" + 0.015*\"شاة_1_0\" + 0.015*\"بينار_0_0\" + 0.014*\"لايك_1_0\" + 0.013*\"كار_1_0\" + 0.012*\"ماه-w_1_0\" + 0.011*\"وه_0_0\"\n",
      "Topic: 4 \n",
      "Words: 0.060*\"ايي_0_0\" + 0.024*\"ربيي_0_0\" + 0.022*\"تهبلل_0_0\" + 0.016*\"استرونج_0_0\" + 0.014*\"والطقعه_0_0\" + 0.014*\"تهببل_0_0\" + 0.010*\"عمرريي_0_0\" + 0.008*\"وبل_1_0\" + 0.008*\"لهه_0_0\" + 0.007*\"وياكك_0_0\"\n",
      "Topic: 5 \n",
      "Words: 0.213*\"طلال_1_0\" + 0.057*\"الوادعي_0_0\" + 0.056*\"بن_2_0\" + 0.053*\"جابر_1_0\" + 0.050*\"شافي_1_0\" + 0.031*\"ميراي_0_0\" + 0.028*\"متسابق_1_0\" + 0.014*\"عبدالقادر_1_0\" + 0.014*\"الحركان_0_0\" + 0.013*\"محسن_2_0\"\n",
      "Topic: 6 \n",
      "Words: 0.013*\"الله_1_0\" + 0.007*\"رياض_1_0\" + 0.005*\"ل_1_0\" + 0.005*\"قلب_3_0\" + 0.005*\"شركة_1_0\" + 0.004*\"دعم_1_0\" + 0.004*\"تنظيف_1_0\" + 0.004*\"أهلي_1_0\" + 0.004*\"رب_1_0\" + 0.004*\"سعودي_1_0\"\n"
     ]
    }
   ],
   "source": [
    "# for each topic, print words occuring in that topic\n",
    "for idx, topic in lda_model_7.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f28b3d",
   "metadata": {},
   "source": [
    "### 4.1.4. LDA with 10 Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95409630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39min 40s, sys: 12min 10s, total: 51min 50s\n",
      "Wall time: 1h 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lda_model_10 = gensim.models.LdaMulticore(bow_corpus, \n",
    "                                         num_topics=10, \n",
    "                                         id2word=dictionary, \n",
    "                                         passes=4, \n",
    "                                         workers=2,\n",
    "                                         random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3643c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save 10-topic model to disk in github repo\n",
    "lda_model_10.save(\"/Users/richard/Desktop/springboard_repo/capstones/three/models/LDA_10_below15_above50_top100k.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe2c2f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.000*\"سِعْر_1\" + 0.000*\"ساعَة_1\" + 0.000*\"طَلَب_1\" + 0.000*\"واتس_0\" + 0.000*\"جَدِيد_1\" + 0.000*\"سَنَة_1\" + 0.000*\"رِياض_1\" + 0.000*\"تَواصُل_1\" + 0.000*\"بَيْع_1\" + 0.000*\"تَسابّ_1\"\n",
      "Topic: 1 \n",
      "Words: 0.000*\"هِلال_3\" + 0.000*\"أَهْلِيّ_1\" + 0.000*\"رتويت_0\" + 0.000*\"سَجَّل_1\" + 0.000*\"نادِي_1\" + 0.000*\"إِعْلان_1\" + 0.000*\"حِساب_2\" + 0.000*\"نَصْر_2\" + 0.000*\"دَوْر_1\" + 0.000*\"تابَع_1\"\n",
      "Topic: 2 \n",
      "Words: 0.013*\"الله_1_0\" + 0.007*\"رياض_1_0\" + 0.005*\"ل_1_0\" + 0.005*\"قلب_3_0\" + 0.005*\"شركة_1_0\" + 0.005*\"دعم_1_0\" + 0.004*\"أهلي_1_0\" + 0.004*\"تنظيف_1_0\" + 0.004*\"رب_1_0\" + 0.004*\"سعودي_1_0\"\n",
      "Topic: 3 \n",
      "Words: 0.208*\"ماكا_0_0\" + 0.123*\"مالتي_0_0\" + 0.075*\"فياغرا_1_0\" + 0.072*\"منوي_1_0\" + 0.041*\"مستخلص_1_0\" + 0.035*\"جانبيهفعال_0_0\" + 0.034*\"والارداف_0_0\" + 0.026*\"أَيّ_2\" + 0.017*\"إذابة_1_0\" + 0.016*\"الملتي_0_0\"\n",
      "Topic: 4 \n",
      "Words: 0.003*\"اللَّه_1\" + 0.001*\"رَبّ_1\" + 0.001*\"اللّٰهُمَّ_1\" + 0.001*\"لِ_1\" + 0.000*\"خَيْر_1\" + 0.000*\"جَعَل-a_1\" + 0.000*\"قَلْب_3\" + 0.000*\"سَعادَة_1\" + 0.000*\"رَحِم-a_1\" + 0.000*\"أَنَّ_1\"\n",
      "Topic: 5 \n",
      "Words: 0.000*\"سَعُودِيّ_1\" + 0.000*\"مِصْر_1\" + 0.000*\"بَلَد_1\" + 0.000*\"قُوَّة_1\" + 0.000*\"دِمَشْق_1\" + 0.000*\"رِيف_1\" + 0.000*\"سُورِيا_1\" + 0.000*\"دَوْلَة_1\" + 0.000*\"شَعْب_1\" + 0.000*\"وَطَن_1\"\n",
      "Topic: 6 \n",
      "Words: 0.000*\"مَشّ_1\" + 0.000*\"حاجَة_1\" + 0.000*\"إِيه_1\" + 0.000*\"كَدّ_1\" + 0.000*\"بِنْت_1\" + 0.000*\"ده_0\" + 0.000*\"دِي_1\" + 0.000*\"أَنَّة_1\" + 0.000*\"مِعَى_1\" + 0.000*\"عاوِز_1\"\n",
      "Topic: 7 \n",
      "Words: 0.000*\"دُون_1\" + 0.000*\"ماء_1\" + 0.000*\"بَنْك_1\" + 0.000*\"جَدّ_1\" + 0.000*\"حَلّ_1\" + 0.000*\"عَسَل_1\" + 0.000*\"قَرْض_1\" + 0.000*\"رِياض_1\" + 0.000*\"نَوْع_1\" + 0.000*\"سَيّارَة_1\"\n",
      "Topic: 8 \n",
      "Words: 0.000*\"صُورَة_1\" + 0.000*\"رَمَضان_1\" + 0.000*\"طِفْل_1\" + 0.000*\"شَهْر_1\" + 0.000*\"عاصِفَة_1\" + 0.000*\"مَدِينَة_1\" + 0.000*\"حَزْم_1\" + 0.000*\"فِيدْيُو_1\" + 0.000*\"مَكَّة_1\" + 0.000*\"عِيد_1\"\n",
      "Topic: 9 \n",
      "Words: 0.000*\"أَفْضَل_2\" + 0.000*\"حِساب_2\" + 0.000*\"ٱِسْتَحَقّ_1\" + 0.000*\"رِياض_1\" + 0.000*\"حَرْف_1\" + 0.000*\"شَرِكَة_1\" + 0.000*\"دَعْم_1\" + 0.000*\"مَنْزِل_1\" + 0.000*\"تويتر_0\" + 0.000*\"أَمِير_2\"\n"
     ]
    }
   ],
   "source": [
    "# for each topic, print words occuring in that topic\n",
    "for idx, topic in lda_model_10.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04633b21",
   "metadata": {},
   "source": [
    "Topic 3 and Topic 8 looks interesting here.\n",
    "- thank you\n",
    "- salman\n",
    "- mohammed\n",
    "- support\n",
    "- Grob\n",
    "- king\n",
    "- prince\n",
    "\n",
    "TOPICS:\n",
    "\n",
    "- Topic 0: Domestic services\n",
    "- Topic 1: Stop words\n",
    "- Topic 2: Service / Used / Buy\n",
    "- Topic 3: Political: Saudi / Qatar / republic\n",
    "- Topic 4: Weight loss\n",
    "- Topic 5: Banks\n",
    "- Topic 6: Religious / Ramadan\n",
    "- Topic 7: Watch offers\n",
    "- Topic 8: Political Saudi\n",
    "- Topic 9: Religious / love"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f333fc79",
   "metadata": {},
   "source": [
    "### 4.1.5. LDA with 15 Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c16e9fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40min 46s, sys: 12min 55s, total: 53min 42s\n",
      "Wall time: 58min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lda_model_15 = gensim.models.LdaMulticore(bow_corpus, \n",
    "                                         num_topics=15, \n",
    "                                         id2word=dictionary, \n",
    "                                         passes=4, \n",
    "                                         workers=2,\n",
    "                                         random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e02a40a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save 15-topic model to disk in github repo\n",
    "lda_model_15.save(\"/Users/richard/Desktop/springboard_repo/capstones/three/models/LDA_15_below15_above50_top100k.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3436f1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.000*\"أثاث_1_0\" + 0.000*\"أفريقيا_1_0\" + 0.000*\"سياسي_1_0\" + 0.000*\"مظلة_1_0\" + 0.000*\"حزام_1_0\" + 0.000*\"سكس_0_0\" + 0.000*\"شراء_1_0\" + 0.000*\"مستعمل_1_0\" + 0.000*\"عالمي_1_0\" + 0.000*\"زد_0_0\"\n",
      "Topic: 1 \n",
      "Words: 0.000*\"سِعْر_1\" + 0.000*\"واتس_0\" + 0.000*\"طَلَب_1\" + 0.000*\"رتويت_0\" + 0.000*\"تَواصُل_1\" + 0.000*\"عَمَل_1\" + 0.000*\"بَيْع_1\" + 0.000*\"مَوْقِع_1\" + 0.000*\"إِعْلان_1\" + 0.000*\"رَجُل_1\"\n",
      "Topic: 2 \n",
      "Words: 0.000*\"طَرِيق_1\" + 0.000*\"واحِد_1\" + 0.000*\"ٱِحْتاج_1\" + 0.000*\"آخَر_1\" + 0.000*\"قِيمَة_1\" + 0.000*\"فُرْصَة_1\" + 0.000*\"ٱِنْتَهَى_1\" + 0.000*\"نِهايَة_1\" + 0.000*\"نَظَر_1\" + 0.000*\"سِنّ_1\"\n",
      "Topic: 3 \n",
      "Words: 0.004*\"اللَّه_1\" + 0.001*\"قال-u_1\" + 0.001*\"ناس_1\" + 0.001*\"رَبّ_1\" + 0.001*\"اللّٰهُمَّ_1\" + 0.000*\"لِ_1\" + 0.000*\"رَحِم-a_1\" + 0.000*\"جَنَّة_1\" + 0.000*\"خَيْر_1\" + 0.000*\"حَمْد_2\"\n",
      "Topic: 4 \n",
      "Words: 0.001*\"لَيّ_1\" + 0.001*\"حُبّ_1\" + 0.000*\"قَلْب_3\" + 0.000*\"لَيْل_1\" + 0.000*\"أَنا_1\" + 0.000*\"عَيْن_3\" + 0.000*\"يِن_1\" + 0.000*\"بُعْد_1\" + 0.000*\"غِياب_1\" + 0.000*\"شَوْق_1\"\n",
      "Topic: 5 \n",
      "Words: 0.001*\"سَعُودِيّ_1\" + 0.000*\"مَلِك_2\" + 0.000*\"مِصْر_1\" + 0.000*\"مُحَمَّد_1\" + 0.000*\"شَعْب_1\" + 0.000*\"وَطَن_1\" + 0.000*\"ال_1\" + 0.000*\"عَبْداللّٰه_1\" + 0.000*\"أَمِير_2\" + 0.000*\"أَهَمّ_2\"\n",
      "Topic: 6 \n",
      "Words: 0.001*\"أَنا_1\" + 0.001*\"بَسّ-u_1\" + 0.001*\"مَشّ_1\" + 0.000*\"حَدّ_1\" + 0.000*\"أُمّ_1\" + 0.000*\"عُشّ_1\" + 0.000*\"إِيه_1\" + 0.000*\"كَدّ_1\" + 0.000*\"بِنْت_1\" + 0.000*\"ده_0\"\n",
      "Topic: 7 \n",
      "Words: 0.000*\"جَدِيد_1\" + 0.000*\"سَنَة_1\" + 0.000*\"دُون_1\" + 0.000*\"ماء_1\" + 0.000*\"بَنْك_1\" + 0.000*\"مُشْكِلَة_1\" + 0.000*\"مَن_1\" + 0.000*\"حَلّ_1\" + 0.000*\"عَسَل_1\" + 0.000*\"قَرْض_1\"\n",
      "Topic: 8 \n",
      "Words: 0.000*\"صُورَة_1\" + 0.000*\"رَمَضان_1\" + 0.000*\"شَهْر_1\" + 0.000*\"بَيْت_3\" + 0.000*\"أَبُو_1\" + 0.000*\"كِتاب_1\" + 0.000*\"عِيد_1\" + 0.000*\"أَحْمَد_1\" + 0.000*\"بَلَغ-u_1\" + 0.000*\"مُسَلْسَل_1\"\n",
      "Topic: 9 \n",
      "Words: 0.001*\"رِياض_1\" + 0.000*\"ساعَة_1\" + 0.000*\"أَفْضَل_2\" + 0.000*\"تَوْصِيل_1\" + 0.000*\"شَرِكَة_1\" + 0.000*\"نَوْم_1\" + 0.000*\"نَوْع_1\" + 0.000*\"مَجّان_1\" + 0.000*\"مَنْزِل_1\" + 0.000*\"جِدّ_1\"\n",
      "Topic: 10 \n",
      "Words: 0.000*\"هِلال_3\" + 0.000*\"أَهْلِيّ_1\" + 0.000*\"مَرَّة_1\" + 0.000*\"سَجَّل_1\" + 0.000*\"كَبِير_1\" + 0.000*\"نادِي_1\" + 0.000*\"كُرَة_1\" + 0.000*\"نَصْر_2\" + 0.000*\"جُمْهُور_1\" + 0.000*\"مُباراة_1\"\n",
      "Topic: 11 \n",
      "Words: 0.000*\"مَدِينَة_1\" + 0.000*\"قُوَّة_1\" + 0.000*\"حَقِيقَة_1\" + 0.000*\"بَلَد_1\" + 0.000*\"أَسَد_1\" + 0.000*\"حَقّ_2\" + 0.000*\"قام-u_1\" + 0.000*\"إِخْوَة_1\" + 0.000*\"أَمْن_1\" + 0.000*\"حُرّ_1\"\n",
      "Topic: 12 \n",
      "Words: 0.020*\"الله_1_0\" + 0.011*\"رياض_1_0\" + 0.009*\"ل_1_0\" + 0.008*\"قلب_3_0\" + 0.008*\"شركة_1_0\" + 0.007*\"دعم_1_0\" + 0.007*\"تنظيف_1_0\" + 0.007*\"أهلي_1_0\" + 0.006*\"رب_1_0\" + 0.006*\"سعودي_1_0\"\n",
      "Topic: 13 \n",
      "Words: 0.000*\"ٱِسْم_1\" + 0.000*\"حِساب_2\" + 0.000*\"طِفْل_1\" + 0.000*\"دِمَشْق_1\" + 0.000*\"ٱِسْتَحَقّ_1\" + 0.000*\"رِيف_1\" + 0.000*\"شُكْر_1\" + 0.000*\"تويتر_0\" + 0.000*\"سُورِيا_1\" + 0.000*\"دَعْم_1\"\n",
      "Topic: 14 \n",
      "Words: 0.001*\"أَنَّ_1\" + 0.001*\"لِ_1\" + 0.001*\"قَلْب_3\" + 0.001*\"أَنْتَ_1\" + 0.001*\"حَياة_1\" + 0.001*\"أَحَبّ_1\" + 0.001*\"كان_1\" + 0.001*\"كُلّ_1\" + 0.001*\"شَيْء_1\" + 0.001*\"نَفْس_1\"\n"
     ]
    }
   ],
   "source": [
    "# for each topic, print words occuring in that topic\n",
    "for idx, topic in lda_model_15.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474fe3b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cap3-topic-modelling",
   "language": "python",
   "name": "cap3-topic-modelling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
